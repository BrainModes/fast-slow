{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was with minor modifications taken from Dubois et al. Phil Trans R Soc B 2018.\n",
    "\n",
    "Code was made available at github:\n",
    "https://github.com/adolphslab/HCP_MRI-behavior/blob/master/intelligence.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HCP_helpers import *\n",
    "%load_ext rpy2.ipython\n",
    "%matplotlib inline\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "library(ggplot2)\n",
    "library(psych)\n",
    "library(lavaan)\n",
    "library(Hmisc)\n",
    "library(corrplot)\n",
    "library(semPlot)\n",
    "library(colorRamps)\n",
    "# Helpers functions\n",
    "# compute Comparative Fit Index for a factor analysis \n",
    "CFI <-function(x){\n",
    "    return((1-((x$STATISTIC-x$dof))/(x$null.chisq-x$null.dof)))\n",
    "}\n",
    "# compute Comparative Fit Index for a bifactor analysis \n",
    "CFI_biv <-function(x){\n",
    "    return((1-((x$stats$STATISTIC-x$stats$dof))/(x$stats$null.chisq-x$stats$null.dof)))\n",
    "}\n",
    "# compute implied matrix for a factor analysis\n",
    "impliedMatrix<-function(x){\n",
    "    if (dim(x$loadings)[2]==1) {\n",
    "        imp      <- x$loadings %*% t(x$loadings) \n",
    "    } else {\n",
    "       imp      <- x$loadings %*% x$Phi %*% t(x$loadings) \n",
    "    }\n",
    "    diag(imp)<- diag(imp) + x$uniquenesses\n",
    "    return(imp)\n",
    "}\n",
    "# compute implied matrix for a bifactor analysis\n",
    "impliedMatrix_biv<-function(x){\n",
    "    Gloadings     <- x$schmid$sl[,1]\n",
    "    Floadings     <- x$schmid$sl[,2:(ncol(x$schmid$sl)-3)]\n",
    "    uniquenesses  <- x$schmid$sl[,ncol(x$schmid$sl)-1]\n",
    "    imp           <- Gloadings %*% t(Gloadings) + Floadings %*% t(Floadings)\n",
    "    diag(imp)     <- diag(imp) + uniquenesses\n",
    "    return(imp)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should figures be saved as files\n",
    "exportFigs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config is a global variable used by several functions\n",
    "# Where does the HCP data live?\n",
    "config.DATADIR                 = '/path/to/data'\n",
    "# Which release should subjects be selected from?\n",
    "config.release                 = 'all+MEG2'\n",
    "# Which resting-state denoising pipeline should be used?\n",
    "# A replicates Finn et al Nature Neuroscience 2015 as closely as possible\n",
    "config.pipelineName            = 'A'\n",
    "# list available runs\n",
    "fmriRuns                       = ['rfMRI_REST1_LR','rfMRI_REST1_RL','rfMRI_REST2_LR','rfMRI_REST2_RL']\n",
    "# which file to use for the functional data?\n",
    "#the code #fMRIrun# will be replaced by the appropriate run\n",
    "config.fmriFileTemplate        = '#fMRIrun#_Atlas_MSMAll.dtseries.nii'\n",
    "## do not alter the following lines ##\n",
    "##>>>>>>>>\n",
    "tmp = config.fmriFileTemplate.split('.')\n",
    "if tmp[1]=='nii':\n",
    "    config.isCifti = False\n",
    "elif tmp[1]=='dtseries':\n",
    "    config.isCifti = True\n",
    "else:\n",
    "    print('unknown file extension')\n",
    "##<<<<<<<<\n",
    "# parcellation for FC matrix\n",
    "config.parcellationName        = 'Glasser' #used for easy reference\n",
    "config.parcellationFile        = '/scratch/duboisjx/data/parcellations/Glasser2016/Parcels.dlabel.nii'\n",
    "config.nParcels                = 360\n",
    "# where are the .csv files with subject scores and info?\n",
    "# unrestricted\n",
    "config.behavFile               = '/path/to/HCP_data/unrestricted_....csv'\n",
    "# RESTRICTED: needed for age, handedness, family structure,...\n",
    "config.RbehavFile              = '/path/to/HCP_data/RESTRICTED_....csv'\n",
    "# other naming conventions\n",
    "config.melodicFolder           = op.join('#fMRIrun#_hp2000.ica','filtered_func_data.ica') \n",
    "config.movementRelativeRMSFile = 'Movement_RelativeRMS.txt'\n",
    "config.movementRegressorsFile  = 'Movement_Regressors_dt.txt'\n",
    "# it is advisable to run the analyses on a cluster with sge\n",
    "config.queue        = True\n",
    "parallelEnvironment = 'smp' #'openmp'\n",
    "# output directory\n",
    "outDir              = op.join(config.DATADIR,'Results','INTELLIGENCE',config.pipelineName,config.parcellationName)\n",
    "if not op.isdir(outDir):\n",
    "    makedirs(outDir)\n",
    "    \n",
    "# if working with volumetric data: should the parcels be restricted to the gray matter mask?\n",
    "if not config.isCifti:\n",
    "    config.maskParcelswithGM       = False\n",
    "    if config.maskParcelswithGM:\n",
    "        config.parcellationName = config.parcellationName + '_GM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ CSV FILES\n",
    "Udf = pd.read_csv(config.behavFile)\n",
    "Rdf = pd.read_csv(config.RbehavFile)\n",
    "# merge unrestricted and restricted\n",
    "df = pd.merge(Udf,Rdf,how='inner')\n",
    "# keep only variables of interest\n",
    "df = df[['Subject','Release','Gender','Age_in_Yrs','fMRI_3T_ReconVrs',\n",
    "         'FS_BrainSeg_Vol','MMSE_Score',\n",
    "        'Family_ID','Father_ID','Mother_ID','Race','Ethnicity','Handedness', \n",
    "        '3T_RS-fMRI_PctCompl','PMAT_Compl','NEO-FFI_Compl','MMSE_Compl',\n",
    "        'Non-TB_Compl','VisProc_Compl','DelDisc_Compl','SCPT_Compl','IWRD_Compl','VSPLOT_Compl', \n",
    "        'NEOFAC_O','NEOFAC_C','NEOFAC_E','NEOFAC_A','NEOFAC_N',\n",
    "        'NEORAW_01','NEORAW_02','NEORAW_03','NEORAW_04','NEORAW_05','NEORAW_06','NEORAW_07','NEORAW_08','NEORAW_09','NEORAW_10',\n",
    "        'NEORAW_11','NEORAW_12','NEORAW_13','NEORAW_14','NEORAW_15','NEORAW_16','NEORAW_17','NEORAW_18','NEORAW_19','NEORAW_20',\n",
    "        'NEORAW_21','NEORAW_22','NEORAW_23','NEORAW_24','NEORAW_25','NEORAW_26','NEORAW_27','NEORAW_28','NEORAW_29','NEORAW_30',\n",
    "        'NEORAW_31','NEORAW_32','NEORAW_33','NEORAW_34','NEORAW_35','NEORAW_36','NEORAW_37','NEORAW_38','NEORAW_39','NEORAW_40',\n",
    "        'NEORAW_41','NEORAW_42','NEORAW_43','NEORAW_44','NEORAW_45','NEORAW_46','NEORAW_47','NEORAW_48','NEORAW_49','NEORAW_50',\n",
    "        'NEORAW_51','NEORAW_52','NEORAW_53','NEORAW_54','NEORAW_55','NEORAW_56','NEORAW_57','NEORAW_58','NEORAW_59','NEORAW_60',\n",
    "        'CardSort_Unadj','Flanker_Unadj','ListSort_Unadj','PicSeq_Unadj','PicVocab_Unadj','ProcSpeed_Unadj','ReadEng_Unadj',\n",
    "        'IWRD_TOT','PMAT24_A_CR','VSPLOT_TC'\n",
    "        ]]\n",
    "# replace labeled columns with dummies\n",
    "df['Gender'].replace(['F','M'],[1,2],inplace=True)\n",
    "df['fMRI_3T_ReconVrs'].replace(['r177','r177 r227','r227'],[1,2,3],inplace=True)\n",
    "\n",
    "# RECOMPUTE PERSONALITY FACTOR SCORES\n",
    "# NOT USED IN THIS ANALYSIS, BUT KEPT FOR CONSISTENCY WITH PERSONALITY PAPER SUBJECT SELECTION\n",
    "scoring = [ \n",
    "    {'13':'n', '23':'r', '43':'n', #aesthetic interests\n",
    "    '48':'r', '53':'n', '58':'n', #intellectual interests\n",
    "    '03':'r', '08':'r', '18':'r', '38':'r', # unconventionality\n",
    "    '28':'n', '33':'r'},#??\n",
    "    {'05':'n', '10':'n', '15':'r', '30':'r', '55':'r', # orderliness\n",
    "    '25':'n', '35':'n', '60':'n', # goal-striving\n",
    "    '20':'n', '40':'n', '45':'r', '50':'n'}, # dependability\n",
    "    {'07':'n', '12':'r', '37':'n', '42':'r', # positive affect\n",
    "   '02':'n', '17':'n', '27':'r', '57':'r', # sociability\n",
    "   '22':'n', '32':'n', '47':'n', '52':'n'}, # activity\n",
    "    {'09':'r', '14':'r', '19':'n', '24':'r', '29':'r', '44':'r', '54':'r', '59':'r', #nonantagonistic orientation\n",
    "   '04':'n', '34':'n', '39':'r', '49':'n'}, # prosocial orientation\n",
    "    {'01':'r', '11':'n', '16':'r', '31':'r', '46':'r', # negative affect\n",
    "   '06':'n', '21':'n', '26':'n', '36':'n', '41':'n', '51':'n', '56':'n'} # self-reproach\n",
    "    ]\n",
    "factors = ['O','C','E','A','N']\n",
    "scoreL  = ['NEOFAC_O', 'NEOFAC_C', 'NEOFAC_E', 'NEOFAC_A_corr', 'NEOFAC_N']\n",
    "diff     = list()\n",
    "for iFac,factor in enumerate(factors):\n",
    "    this       = np.zeros(df.shape[0])\n",
    "    keyCtr = -1\n",
    "    for key in scoring[iFac].keys():\n",
    "        if scoring[iFac][key]=='n':\n",
    "            df['NEORAW_'+key].replace(['SD','D','N','A','SA'],[0,1,2,3,4],inplace=True)\n",
    "        else:\n",
    "            df['NEORAW_'+key].replace(['SD','D','N','A','SA'],[4,3,2,1,0],inplace=True)\n",
    "        this = this + df['NEORAW_'+key]\n",
    "        keyCtr += 1\n",
    "    df['NEOFAC_'+factor+'_calc']=this\n",
    "    diff.append(np.sum(np.abs(df['NEOFAC_'+factor]-df['NEOFAC_'+factor+'_calc'])))\n",
    "print('diffO={0:d}, diffC={1:d}, diffE={2:d}, diffA={3:d}, diffN={4:d}'.format(\n",
    "    np.int(diff[0]),np.int(diff[1]),np.int(diff[2]),np.int(diff[3]),np.int(diff[4])))\n",
    "# correct scores\n",
    "df['NEOFAC_A_corr']  = df['NEOFAC_A_calc']\n",
    "\n",
    "# select subjects according to release\n",
    "if config.release == 'Q2':\n",
    "    keepSub = (df['Release'] == 'Q2') | (df['Release'] == 'Q1')\n",
    "elif config.release == 'S500':\n",
    "    keepSub = (df['Release'] == 'Q3') | (df['Release'] == 'S500')\n",
    "elif config.release == 'Q2+S500':\n",
    "    keepSub = (df['Release'] == 'Q2') | (df['Release'] == 'Q1') | (df['Release'] == 'Q3') | (df['Release'] == 'S500')\n",
    "elif config.release == 'S900':\n",
    "    keepSub = (df['Release'] == 'S900')\n",
    "elif config.release == 'S1200':\n",
    "    keepSub = (df['Release'] == 'S1200')\n",
    "elif config.release == 'all':\n",
    "    keepSub = ((df['Release'] == 'Q1') | (df['Release'] == 'Q2') | (df['Release'] == 'Q3') \n",
    "           | (df['Release'] == 'S500') | (df['Release'] == 'S900') | (df['Release'] == 'S1200'))\n",
    "elif config.release == 'all+MEG2':\n",
    "    keepSub = ((df['Release'] == 'Q1') | (df['Release'] == 'Q2') | (df['Release'] == 'Q3') \n",
    "           | (df['Release'] == 'S500') | (df['Release'] == 'S900') | (df['Release'] == 'S1200') \n",
    "           | (df['Release'] == 'MEG2'))\n",
    "else:\n",
    "    sys.exit(\"Invalid release code\")\n",
    "print('Selected {} subjects for release {}'.format(np.sum(keepSub),config.release))\n",
    "\n",
    "# select subjects that have completed all neuropsych\n",
    "keepSub = keepSub & (\n",
    "    (df['PMAT_Compl']==True) &\n",
    "    (df['NEO-FFI_Compl']==True) &\n",
    "    (df['MMSE_Compl']==True) &\n",
    "    (df['Non-TB_Compl']==True) &\n",
    "    (df['VisProc_Compl']==True) &\n",
    "    (df['SCPT_Compl']==True) &\n",
    "    (df['IWRD_Compl']==True) &\n",
    "    (df['VSPLOT_Compl']==True)\n",
    "    )\n",
    "print('Selected {} subjects with complete neuropsych data'.format(np.sum(keepSub)))\n",
    "\n",
    "# FURTHER EXCLUSIONARY CRITERIA: MISSING VALUES\n",
    "keepSub    = np.logical_and(keepSub,np.logical_not(np.isnan(df['CardSort_Unadj'])))\n",
    "keepSub    = np.logical_and(keepSub,np.logical_not(np.isnan(df['VSPLOT_TC'])))\n",
    "keepSub    = np.logical_and(keepSub,np.logical_not(np.isnan(df['PicSeq_Unadj'])))\n",
    "keepSub    = np.logical_and(keepSub,np.logical_not(np.isnan(df['NEORAW_01'])))\n",
    "print('Kept {} subjects after removing missing values'.format(np.sum(keepSub)))\n",
    "\n",
    "# COGNITIVE COMPROMISE --> MMSE <26 excluded\n",
    "keepSub    = np.logical_and(keepSub,df['MMSE_Score']>=26)\n",
    "print('Kept {} subjects after MMSE<26 exclusion criterion'.format(np.sum(keepSub)))\n",
    "\n",
    "# PRUNE df \n",
    "df        = df[keepSub]\n",
    "# reindex\n",
    "df.index  = range(df.shape[0])\n",
    "\n",
    "print('Included data for FACTOR ANALYSIS: {} subjects [{} F, {:0.1f}+/-{:0.1f} range {}-{} y.o.]'.format(\n",
    "    len(df),np.sum(df['Gender']==1),np.mean(df['Age_in_Yrs']),np.std(df['Age_in_Yrs']),np.min(df['Age_in_Yrs']),np.max(df['Age_in_Yrs'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cogScores = ['PicVocab_Unadj',              # Vocabulary, Language, Crystallized, Global\n",
    "             'ReadEng_Unadj',               # Reading, Language, Crystallized, Global\n",
    "             'PicSeq_Unadj',                # Episodic memory, Fluid, Global\n",
    "             'Flanker_Unadj',               # Executive, Fluid, Global\n",
    "             'CardSort_Unadj',              # Executive, Fluid, Global\n",
    "             'ProcSpeed_Unadj',             # Speed, Executive, Fluid, Global\n",
    "             'PMAT24_A_CR',                 # non-verbal reasoning: Number of Correct Responses, Median Reaction Time for Correct Responses \n",
    "             'VSPLOT_TC',                   # Spatial ability: Total Number Correct, Median Reaction Time Divided by Expected Number of Clicks for Correct \n",
    "             'IWRD_TOT',                    # Verbal memory\n",
    "             'ListSort_Unadj',              # Working memory, Executive, Fluid, Global\n",
    "        ]\n",
    "alpha = 1e-3\n",
    "for score in cogScores:\n",
    "    k2, p = stats.normaltest(df[score])\n",
    "    print(\"{} normality test: p = {:g}\".format(score,p))\n",
    "cogdf      = df[cogScores].copy()\n",
    "\n",
    "# standardize scores\n",
    "standardize = lambda x: (x-x.mean()) / x.std() #* 15. + 100.\n",
    "cogdf = cogdf.pipe(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrfunc(x, y, **kws):\n",
    "    cmap = matplotlib.cm.get_cmap('jet')\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.text(0.5, 0.5, \"{:.2f}\".format(r), size=48, ha='center', va='center')\n",
    "    ax.set_axis_bgcolor(cmap((r+1)/2))\n",
    "    ax.spines['left'].set_visible(False) \n",
    "    ax.spines['bottom'].set_visible(False) \n",
    "def diagfunc(x, **kws):\n",
    "    ax = plt.gca()\n",
    "    ylims = ax.get_ylim()\n",
    "    ax.text(0.5, ylims[0]+0.9*(ylims[1]-ylims[0]), x.name, size=24, ha='center', va='center')\n",
    "    ax.spines['left'].set_visible(False) \n",
    "\n",
    "g = sns.PairGrid(cogdf, palette=[\"red\"])\n",
    "g.map_upper(plt.scatter, s=10)\n",
    "g.map_diag(sns.distplot, kde=False)\n",
    "g.map_diag(diagfunc)\n",
    "g.map_lower(corrfunc)\n",
    "\n",
    "lims = (-4,4)\n",
    "for ax in g.axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "if exportFigs:\n",
    "    plt.savefig(op.join(outDir,\"testCorr.svg\"), format='svg')\n",
    "    \n",
    "# cmap = matplotlib.cm.get_cmap('jet')\n",
    "# c = np.random.random((10,10))\n",
    "# sns.heatmap(c,annot=True, fmt=\".2f\", cmap=cmap, vmin=-1,vmax=1)\n",
    "# if exportFigs:\n",
    "#     plt.savefig(\"/scratch/duboisjx/testCorrCBAR.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i cogdf -o faValues,faSim,faSimR \n",
    "\n",
    "out = fa.parallel(cogdf,plot=F)#error.bars=T,se.bars=F,\n",
    "faValues = out$fa.values\n",
    "faSim    = out$fa.sim\n",
    "faSimR   = out$fa.simr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.plot(np.arange(10)+1,faSim,'r:',label='simulated data');\n",
    "ax.plot(np.arange(10)+1,faSimR,'r--',label='resampled data');\n",
    "ax.plot(np.arange(10)+1,faValues,'b^-',label='actual data');\n",
    "ax.axhline(y=1,linestyle='-',color='k')\n",
    "plt.setp(ax,xlabel='Factor #',ylabel='eigenvalues of factor analysis',xlim=(0.5,10.5));\n",
    "plt.legend()\n",
    "\n",
    "if exportFigs:\n",
    "    plt.savefig(op.join(outDir,\"faParallel.svg\"), format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "library(ggplot2)\n",
    "library(psych)\n",
    "library(lavaan)\n",
    "library(Hmisc)\n",
    "library(corrplot)\n",
    "library(semPlot)\n",
    "#library(colorRamps)\n",
    "# Helpers functions\n",
    "# compute Comparative Fit Index for a factor analysis \n",
    "CFI <-function(x){\n",
    "    return((1-((x$STATISTIC-x$dof))/(x$null.chisq-x$null.dof)))\n",
    "}\n",
    "# compute Comparative Fit Index for a bifactor analysis \n",
    "CFI_biv <-function(x){\n",
    "    return((1-((x$stats$STATISTIC-x$stats$dof))/(x$stats$null.chisq-x$stats$null.dof)))\n",
    "}\n",
    "# compute implied matrix for a factor analysis\n",
    "impliedMatrix<-function(x){\n",
    "    if (dim(x$loadings)[2]==1) {\n",
    "        imp      <- x$loadings %*% t(x$loadings) \n",
    "    } else {\n",
    "       imp      <- x$loadings %*% x$Phi %*% t(x$loadings) \n",
    "    }\n",
    "    diag(imp)<- diag(imp) + x$uniquenesses\n",
    "    return(imp)\n",
    "}\n",
    "# compute implied matrix for a bifactor analysis\n",
    "impliedMatrix_biv<-function(x){\n",
    "    Gloadings     <- x$schmid$sl[,1]\n",
    "    Floadings     <- x$schmid$sl[,2:(ncol(x$schmid$sl)-3)]\n",
    "    uniquenesses  <- x$schmid$sl[,ncol(x$schmid$sl)-1]\n",
    "    imp           <- Gloadings %*% t(Gloadings) + Floadings %*% t(Floadings)\n",
    "    diag(imp)     <- diag(imp) + uniquenesses\n",
    "    return(imp)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "fm     <- \"mle\"       # use maximum likelihood estimator\n",
    "rotate <- \"oblimin\"   # use oblimin factor rotation\n",
    "\n",
    "fitInds <- matrix(, nrow = 2, ncol = 9)\n",
    "rownames(fitInds) <- c('s1','b4')\n",
    "colnames(fitInds) <- c('CFI','RMSEA','SRMR','BIC','om_h','om_s1','om_s2','om_s3','om_s4')\n",
    "\n",
    "# observed covariance matrices\n",
    "obs       <-  cov(cogdf)\n",
    "lobs      <-  obs[!lower.tri(obs)]\n",
    "\n",
    "#SINGLE FACTOR\n",
    "model = 1\n",
    "f1     <- fa(cogdf,nfactors=1)\n",
    "imp    <-  impliedMatrix(f1)\n",
    "limp   <-  imp[!lower.tri(imp)]\n",
    "fitInds[model,1] <-  CFI(f1)\n",
    "fitInds[model,2] <-  f1$RMSEA[1]\n",
    "fitInds[model,3] <-  sqrt(mean((limp - lobs)^2))\n",
    "fitInds[model,4] <-  f1$BIC\n",
    "\n",
    "# BI-FACTOR MODEL\n",
    "model = 2\n",
    "b4      <- omega(cogdf,nfactors=4,fm=fm,key=NULL,flip=FALSE,\n",
    "        digits=3,title=\"Omega\",sl=TRUE,labels=NULL, plot=FALSE,\n",
    "        n.obs=NA,rotate=rotate,Phi = NULL,option=\"equal\",covar=FALSE)\n",
    "imp     <-  impliedMatrix_biv(b4)\n",
    "limp    <-  imp[!lower.tri(imp)]\n",
    "fitInds[model,1] <-  CFI_biv(b4)\n",
    "fitInds[model,2] <-  b4$schmid$RMSEA[1]\n",
    "fitInds[model,3] <-  sqrt(mean((limp - lobs)^2))\n",
    "fitInds[model,4] <-  b4$stats$BIC\n",
    "fitInds[model,5] <-  b4$omega_h\n",
    "fitInds[model,6:9] <-  b4$omega.group[-1,3]\n",
    "\n",
    "print(fitInds,digits=3)\n",
    "\n",
    "print(b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 500 -h 500 -o b4Scores\n",
    "\n",
    "diagram(b4,digits=3,cut=.2)\n",
    "# export scores\n",
    "b4Scores    <- factor.scores(cogdf,b4$schmid$sl[,1:5])$scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = df['Subject'].values\n",
    "g_factor = b4Scores[:,0]\n",
    "\n",
    "flank=cogdf['Flanker_Unadj']\n",
    "ccs = [np.corrcoef(b4Scores[:,ii],flank)[0,1] for ii in range(b4Scores.shape[1])]\n",
    "which_spd = np.where(np.array(ccs) > 0.79)[0][0]\n",
    "spd = b4Scores[:,which_spd]\n",
    "\n",
    "\n",
    "picvoc=cogdf['PicVocab_Unadj']\n",
    "ccs = [np.corrcoef(b4Scores[:,ii],picvoc)[0,1] for ii in range(b4Scores.shape[1])]\n",
    "which_picvoc = np.where(np.array(ccs) > 0.83)[0][0]\n",
    "cry = b4Scores[:,which_picvoc]\n",
    "\n",
    "\n",
    "pmat=cogdf['PMAT24_A_CR']\n",
    "ccs = [np.corrcoef(b4Scores[:,ii],pmat)[0,1] for ii in range(b4Scores.shape[1])]\n",
    "which_pmat = np.where(np.array(ccs[1:]) > 0.54)[0][0]\n",
    "which_pmat = which_pmat+1\n",
    "vis = b4Scores[:,which_pmat]\n",
    "\n",
    "\n",
    "picseq=cogdf['PicSeq_Unadj']\n",
    "ccs = [np.corrcoef(b4Scores[:,ii],picseq)[0,1] for ii in range(b4Scores.shape[1])]\n",
    "which_picseq = np.where(np.array(ccs) > 0.9)[0][0]\n",
    "mem = b4Scores[:,which_picseq]\n",
    "ccs\n",
    "\n",
    "\n",
    "print(which_spd,which_picvoc,which_pmat, which_picseq)\n",
    "print(ccs)\n",
    "\n",
    "from scipy.io import savemat\n",
    "savemat('g_asin_Dubois2018.mat', \n",
    "        {\"g_factor\" : g_factor,\n",
    "         \"subjects\" : subjects,\n",
    "         \"spd\" : spd,\n",
    "         \"cry\" : cry,\n",
    "         \"mem\" : mem,\n",
    "         \"vis\" : vis\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
